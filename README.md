# wetext-rs

[![Crates.io](https://img.shields.io/crates/v/wetext-rs.svg)](https://crates.io/crates/wetext-rs)
[![Documentation](https://docs.rs/wetext-rs/badge.svg)](https://docs.rs/wetext-rs)
[![License](https://img.shields.io/crates/l/wetext-rs.svg)](https://github.com/SpenserCai/wetext-rs/blob/main/LICENSE)
[![Rust](https://img.shields.io/badge/rust-1.70%2B-orange.svg)](https://www.rust-lang.org)

A Rust implementation of [WeText](https://github.com/pengzhendong/wetext) for text normalization in TTS (Text-to-Speech) applications.

---

## Table of Contents

- [wetext-rs](#wetext-rs)
  - [Table of Contents](#table-of-contents)
  - [Background](#background)
  - [Features](#features)
  - [Installation](#installation)
  - [FST Weight Files](#fst-weight-files)
    - [Download Options](#download-options)
  - [Usage](#usage)
    - [Basic Usage](#basic-usage)
    - [With Configuration](#with-configuration)
    - [Inverse Text Normalization (ITN)](#inverse-text-normalization-itn)
    - [Convenience Function](#convenience-function)
  - [Configuration Options](#configuration-options)
  - [Examples](#examples)
    - [Chinese Text Normalization](#chinese-text-normalization)
    - [Chinese Inverse Text Normalization](#chinese-inverse-text-normalization)
    - [English Text Normalization](#english-text-normalization)
    - [Japanese Text Normalization](#japanese-text-normalization)
  - [Dependencies](#dependencies)
  - [Compatibility with Python WeText](#compatibility-with-python-wetext)
  - [Development](#development)
    - [Running Tests](#running-tests)
    - [Consistency Testing with Python WeText](#consistency-testing-with-python-wetext)
    - [Code Quality](#code-quality)
  - [Credits](#credits)
  - [License](#license)

---

## Background

This project is a Rust port of the Python [wetext](https://github.com/pengzhendong/wetext) library, which provides a lightweight runtime for WeTextProcessing without depending on Pynini. The primary motivation for creating this Rust implementation is to:

1. **Integrate with the Candle ecosystem** - Enable seamless integration with Rust-based ML frameworks like [Candle](https://github.com/huggingface/candle), eliminating Python dependencies in production deployments
2. **Improve performance** - Leverage Rust's memory safety and zero-cost abstractions for faster text processing
3. **Enable standalone deployment** - Create a single binary that can be deployed without Python runtime

The original Python implementation uses [kaldifst](https://github.com/k2-fsa/kaldifst) for FST operations. This Rust version uses [rustfst](https://github.com/Garvys/rustfst), a pure Rust implementation of OpenFST, to achieve the same functionality.

---

## Features

- **Text Normalization (TN)**: Convert numbers, dates, currency to spoken form
  - `"2024å¹´1æœˆ15æ—¥"` â†’ `"äºŒé›¶äºŒå››å¹´ä¸€æœˆåäº”æ—¥"`
  - `"$100"` â†’ `"one hundred dollars"`
- **Inverse Text Normalization (ITN)**: Convert spoken form back to written form
  - `"ä¸€ç™¾äºŒåä¸‰"` â†’ `"123"`
- **Multi-language support**: Chinese (zh), English (en), Japanese (ja)
- **English contractions expansion**: `"don't"` â†’ `"do not"`
- **Various text preprocessing options**:
  - Traditional to Simplified Chinese conversion
  - Full-width to half-width character conversion
  - Interjection removal
  - Punctuation removal
  - Erhua (å„¿åŒ–éŸ³) removal

---

## Installation

Add to your `Cargo.toml`:

```toml
[dependencies]
wetext-rs = "0.1"
```

---

## FST Weight Files

This library requires FST (Finite State Transducer) weight files for text normalization. The weight files can be downloaded from:

> **ModelScope**: [pengzhendong/wetext](https://modelscope.cn/models/pengzhendong/wetext)

Download the weight files and organize them in the following structure:

<details>
<summary>ğŸ“ Click to expand directory structure</summary>

```
fsts/
â”œâ”€â”€ traditional_to_simple.fst
â”œâ”€â”€ full_to_half.fst
â”œâ”€â”€ remove_interjections.fst
â”œâ”€â”€ remove_puncts.fst
â”œâ”€â”€ tag_oov.fst
â”œâ”€â”€ en/
â”‚   â””â”€â”€ tn/
â”‚       â”œâ”€â”€ tagger.fst
â”‚       â””â”€â”€ verbalizer.fst
â”œâ”€â”€ zh/
â”‚   â”œâ”€â”€ tn/
â”‚   â”‚   â”œâ”€â”€ tagger.fst
â”‚   â”‚   â”œâ”€â”€ verbalizer.fst
â”‚   â”‚   â””â”€â”€ verbalizer_remove_erhua.fst
â”‚   â””â”€â”€ itn/
â”‚       â”œâ”€â”€ tagger.fst
â”‚       â”œâ”€â”€ tagger_enable_0_to_9.fst
â”‚       â””â”€â”€ verbalizer.fst
â””â”€â”€ ja/
    â”œâ”€â”€ tn/
    â”‚   â”œâ”€â”€ tagger.fst
    â”‚   â””â”€â”€ verbalizer.fst
    â””â”€â”€ itn/
        â”œâ”€â”€ tagger.fst
        â”œâ”€â”€ tagger_enable_0_to_9.fst
        â””â”€â”€ verbalizer.fst
```

</details>

### Download Options

**Option 1: ModelScope CLI**

```bash
pip install modelscope
modelscope download --model pengzhendong/wetext --local_dir ./fsts
```

**Option 2: Git LFS**

```bash
git lfs install
git clone https://www.modelscope.cn/pengzhendong/wetext.git fsts
```

---

## Usage

### Basic Usage

```rust
use wetext_rs::{Normalizer, NormalizerConfig, Language, Operator};

// Create normalizer with default settings (Chinese TN, auto language detection)
let mut normalizer = Normalizer::with_defaults("path/to/fsts");

// Normalize text
let result = normalizer.normalize("2024å¹´1æœˆ15æ—¥").unwrap();
println!("{}", result);  // äºŒé›¶äºŒå››å¹´ä¸€æœˆåäº”æ—¥
```

### With Configuration

```rust
use wetext_rs::{Normalizer, NormalizerConfig, Language, Operator};

// Configure for specific language and operation
let config = NormalizerConfig::new()
    .with_lang(Language::Zh)
    .with_operator(Operator::Tn)
    .with_fix_contractions(true)
    .with_traditional_to_simple(true);

let mut normalizer = Normalizer::new("path/to/fsts", config);
let result = normalizer.normalize("100å…ƒ").unwrap();
println!("{}", result);  // ä¸€ç™¾å…ƒ
```

### Inverse Text Normalization (ITN)

```rust
use wetext_rs::{Normalizer, NormalizerConfig, Language, Operator};

let config = NormalizerConfig::new()
    .with_lang(Language::Zh)
    .with_operator(Operator::Itn);

let mut normalizer = Normalizer::new("path/to/fsts", config);
let result = normalizer.normalize("ä¸€ç™¾äºŒåä¸‰").unwrap();
println!("{}", result);  // 123
```

### Convenience Function

```rust
use wetext_rs::normalize;

let result = normalize("path/to/fsts", "123").unwrap();
println!("{}", result);  // å¹ºäºŒä¸‰
```

---

## Configuration Options

| Option | Default | Description |
|:-------|:-------:|:------------|
| `lang` | `Auto` | Language: `Auto`, `En`, `Zh`, `Ja` |
| `operator` | `Tn` | Operation: `Tn` (text normalization), `Itn` (inverse) |
| `fix_contractions` | `false` | Expand English contractions |
| `traditional_to_simple` | `false` | Convert Traditional to Simplified Chinese |
| `full_to_half` | `false` | Convert full-width to half-width characters |
| `remove_interjections` | `false` | Remove interjections (e.g., "å—¯", "å•Š") |
| `remove_puncts` | `false` | Remove punctuation marks |
| `tag_oov` | `false` | Tag out-of-vocabulary words |
| `enable_0_to_9` | `false` | Enable 0-9 digit conversion in ITN |
| `remove_erhua` | `false` | Remove erhua (å„¿åŒ–éŸ³) |

---

## Examples

### Chinese Text Normalization

| Input | Output |
|:------|:-------|
| `123` | `å¹ºäºŒä¸‰` |
| `2024å¹´` | `äºŒé›¶äºŒå››å¹´` |
| `2024å¹´1æœˆ15æ—¥` | `äºŒé›¶äºŒå››å¹´ä¸€æœˆåäº”æ—¥` |
| `ä¸‹åˆ3ç‚¹30åˆ†` | `ä¸‹åˆä¸‰ç‚¹ä¸‰ååˆ†` |
| `100å…ƒ` | `ä¸€ç™¾å…ƒ` |
| `3/4` | `å››åˆ†ä¹‹ä¸‰` |
| `1.5` | `ä¸€ç‚¹äº”` |

### Chinese Inverse Text Normalization

| Input | Output |
|:------|:-------|
| `ä¸€ç™¾äºŒåä¸‰` | `123` |
| `äºŒé›¶äºŒå››å¹´` | `2024å¹´` |
| `ä¸€ç‚¹äº”` | `1.5` |

### English Text Normalization

| Input | Output |
|:------|:-------|
| `$100` | `one hundred dollars` |
| `January 15, 2024` | `january fifteenth twenty twenty four` |
| `3.14` | `three point one four` |

### Japanese Text Normalization

| Input | Output |
|:------|:-------|
| `100å††` | `ç™¾å††` |
| `2024å¹´` | `äºŒåƒäºŒåå››å¹´` |
| `3æœˆ15æ—¥` | `ä¸‰æœˆåäº”æ—¥` |

---

## Dependencies

| Crate | Purpose |
|:------|:--------|
| [rustfst](https://github.com/Garvys/rustfst) | FST operations (Rust implementation of OpenFST) |
| [thiserror](https://github.com/dtolnay/thiserror) | Error handling |
| [regex](https://github.com/rust-lang/regex) | Regular expressions |
| [once_cell](https://github.com/matklad/once_cell) | Lazy initialization |
| [serde_json](https://github.com/serde-rs/json) | JSON parsing |

---

## Compatibility with Python WeText

This Rust implementation is designed to be compatible with the Python [wetext](https://github.com/pengzhendong/wetext) library. The core TN/ITN functionality produces identical results for the same inputs.

**Differences from Python version:**

| Aspect | Python wetext | Rust wetext-rs |
|:-------|:--------------|:---------------|
| Language detection | Chinese/English only | Adds Japanese detection (via Hiragana/Katakana) |
| Contractions | Runtime loaded | Compile-time embedded |
| Error handling | Python exceptions | `Result<T, WeTextError>` |
| FST library | kaldifst | rustfst |

---

## Development

### Running Tests

```bash
# Run all unit and integration tests
cargo test

# Run with verbose output
cargo test -- --nocapture
```

### Consistency Testing with Python WeText

To verify that the Rust implementation produces identical results to the Python version:

<details>
<summary>ğŸ§ª Click to expand testing instructions</summary>

1. **Setup Python environment** (Python 3.13 recommended):

```bash
cd tests
python3.13 -m venv venv
source venv/bin/activate
pip install wetext
```

2. **Generate reference outputs** from Python:

```bash
python tests/generate_reference.py
```

This creates `tests/reference_outputs.json` with expected outputs from Python wetext.

3. **Run comparison tests**:

```bash
cargo test test_compare_with_python -- --ignored --nocapture
```

Expected output:

```
âœ“ PASS: '123' (zh/tn) => 'å¹ºäºŒä¸‰'
âœ“ PASS: '2024å¹´1æœˆ15æ—¥' (zh/tn) => 'äºŒé›¶äºŒå››å¹´ä¸€æœˆåäº”æ—¥'
...
Results: 20 passed, 0 failed
```

</details>

### Code Quality

```bash
# Run clippy linter
cargo clippy -- -D warnings

# Format code
cargo fmt

# Check formatting
cargo fmt -- --check
```

---

## Credits

- **Original Python implementation**: [pengzhendong/wetext](https://github.com/pengzhendong/wetext)
- **FST weight files**: [ModelScope - pengzhendong/wetext](https://modelscope.cn/models/pengzhendong/wetext)
- **WeTextProcessing grammar**: [wenet-e2e/WeTextProcessing](https://github.com/wenet-e2e/WeTextProcessing)

---

## License

This project is licensed under the [Apache-2.0 License](LICENSE).
